{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOp+IhGjipsEEYR8f6g5haM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kraakan/TurkuNLP/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E5sAlAXee8o",
        "outputId": "efe9c9b0-5386-4ddb-8eb3-a0b75a6ba2a0"
      },
      "source": [
        "!wget http://dl.turkunlp.org/intro-to-nlp.tar.gz\r\n",
        "\r\n",
        "!tar -zvxf intro-to-nlp.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-29 10:33:55--  http://dl.turkunlp.org/intro-to-nlp.tar.gz\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76192539 (73M) [application/octet-stream]\n",
            "Saving to: ‘intro-to-nlp.tar.gz’\n",
            "\n",
            "intro-to-nlp.tar.gz 100%[===================>]  72.66M  17.9MB/s    in 4.6s    \n",
            "\n",
            "2021-01-29 10:34:00 (15.8 MB/s) - ‘intro-to-nlp.tar.gz’ saved [76192539/76192539]\n",
            "\n",
            "intro-to-nlp/\n",
            "intro-to-nlp/fi.segmenter.udpipe\n",
            "intro-to-nlp/requirements.txt\n",
            "intro-to-nlp/en.segmenter.udpipe\n",
            "intro-to-nlp/sv.segmenter.udpipe\n",
            "intro-to-nlp/finnish-tweets-sample.jsonl.gz\n",
            "intro-to-nlp/imdb_train.json\n",
            "intro-to-nlp/english-tweets-sample.jsonl.gz\n",
            "intro-to-nlp/language-identification/\n",
            "intro-to-nlp/language-identification/pt_test.txt\n",
            "intro-to-nlp/language-identification/et_train.txt\n",
            "intro-to-nlp/language-identification/fi_train.txt\n",
            "intro-to-nlp/language-identification/fi_devel.txt\n",
            "intro-to-nlp/language-identification/et_devel.txt\n",
            "intro-to-nlp/language-identification/es_test.txt\n",
            "intro-to-nlp/language-identification/es_train.txt\n",
            "intro-to-nlp/language-identification/pt_train.txt\n",
            "intro-to-nlp/language-identification/fi_test.txt\n",
            "intro-to-nlp/language-identification/es_devel.txt\n",
            "intro-to-nlp/language-identification/pt_devel.txt\n",
            "intro-to-nlp/language-identification/en_devel.txt\n",
            "intro-to-nlp/language-identification/en_test.txt\n",
            "intro-to-nlp/language-identification/et_test.txt\n",
            "intro-to-nlp/language-identification/en_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jokFTcdUgEnN",
        "outputId": "5037f72e-6861-46c3-85a7-91bd665e8ac3"
      },
      "source": [
        "import glob\r\n",
        "import os\r\n",
        "import sklearn\r\n",
        "import gzip\r\n",
        "import json\r\n",
        "all_files=glob.glob(\"/content/intro-to-nlp/language-identification/*.txt\")\r\n",
        "for fn in all_files:\r\n",
        "  print(os.path.basename(fn))\r\n",
        "  base=os.path.basename(fn).split(\"_\")[0]\r\n",
        "  print(base)\r\n",
        "\r\n",
        "def read_data(lang, section):\r\n",
        "  fn=f\"/content/intro-to-nlp/language-identification/{lang}_{section}.txt\"\r\n",
        "  with open(fn) as f:\r\n",
        "l=[1,2,3,4]\r\n",
        "l.extend([5,6,7,8])\r\n",
        "# remember to shuffle data\r\n",
        "# scikit has a very nice learning curve plotter\r\n",
        "f = gzip.open(/content/intro-to-nlp/english-tweets-sample.jsonl.gz/intro-to-nlp.tar.gz)\r\n",
        "\r\n",
        "sklearn.feature_extraction.text.TfidfVectorizer('filename', f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "es_devel.txt\n",
            "es\n",
            "fi_test.txt\n",
            "fi\n",
            "pt_train.txt\n",
            "pt\n",
            "et_test.txt\n",
            "et\n",
            "fi_devel.txt\n",
            "fi\n",
            "pt_devel.txt\n",
            "pt\n",
            "es_train.txt\n",
            "es\n",
            "et_devel.txt\n",
            "et\n",
            "en_devel.txt\n",
            "en\n",
            "en_train.txt\n",
            "en\n",
            "es_test.txt\n",
            "es\n",
            "fi_train.txt\n",
            "fi\n",
            "en_test.txt\n",
            "en\n",
            "et_train.txt\n",
            "et\n",
            "pt_test.txt\n",
            "pt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}